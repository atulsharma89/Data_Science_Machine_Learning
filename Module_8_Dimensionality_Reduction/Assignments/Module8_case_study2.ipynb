{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case Study\n",
    "Objective:\n",
    "â€¢ Understand and practice linear discriminant analysis using scikit learn.\n",
    "\n",
    "Questions:\n",
    "    \n",
    "1. We shall use the same dataset used in previous assignment - digits. Make a 80- 20 train/test split.\n",
    "[Hint: Explore datasets module from scikit learn]\n",
    "\n",
    "2. Using scikit learn perform a LDA on the dataset. Find out the number of components in the projected subspace.\n",
    "[Hint: Refer to discriminant analysis module of scikit learn]\n",
    "\n",
    "3. Transform the dataset and fit a logistic regression and observe the accuracy. Compare it \n",
    "with the previous model based on PCA in terms of accuracy and model complexity.\n",
    "[Hint: Project both the train and test samples to the new subspace]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "\n",
    "# Create feature matrix\n",
    "X = digits.data\n",
    "\n",
    "# Create target vector\n",
    "y = digits.target\n",
    "\n",
    "# View the first observation's feature values\n",
    "X[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "print(digits.data.shape)\n",
    "print(digits.target.shape)\n",
    "#print(digits.COL_NAMES)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = 10, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atul595525/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2. Using scikit learn perform a LDA on the dataset. Find out the number of components in the projected subspace.\n",
    "[Hint: Refer to discriminant analysis module of scikit learn]\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "In the script above the LinearDiscriminantAnalysis class is imported as LDA. \n",
    "Like PCA, we have to pass the value for the n_components parameter of the LDA, \n",
    "which refers to the number of linear discriminates that we want to retrieve. \n",
    "In this case we set the n_components to 1, since we first want to check the performance of our classifier \n",
    "with a single linear discriminant. Finally we execute the fit and transform methods to actually retrieve \n",
    "the linear discriminants.\n",
    "\n",
    "Notice, in case of LDA, the transform method takes two parameters: the X_train and the y_train. \n",
    "However in the case of PCA, the transform method only requires one parameter i.e. X_train. \n",
    "This reflects the fact that LDA takes the output class labels into account while selecting the linear discriminants, \n",
    "while PCA doesn't depend upon the output labels.\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=5)\n",
    "x_train = lda.fit_transform(x_train, y_train)\n",
    "x_test = lda.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training and Making Predictions\n",
    "Since we want to compare the performance of LDA with one linear discriminant to the performance of PCA \n",
    "with one principal component, we will use the same Random Forest classifier that we used to evaluate performance of \n",
    "PCA-reduced algorithms.\n",
    "\n",
    "Execute the following code:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ln_model = LogisticRegression()\n",
    "\n",
    "ln_model.fit(x_train, y_train)\n",
    "\n",
    "#classifier.fit(X_train, y_train)\n",
    "y_pred = ln_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 29  1  0  0  0  2  0  2  0]\n",
      " [ 0  0 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  2 37  0  0  0  0  1  0]\n",
      " [ 1  2  0  0 29  0  1  0  0  1]\n",
      " [ 0  0  0  2  0 29  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 36  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 39  0  0]\n",
      " [ 0  9  1  0  0  0  0  0 22  1]\n",
      " [ 1  0  0  4  0  0  0  0  1 33]]\n",
      "Accuracy0.9\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Performance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy' + str(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
