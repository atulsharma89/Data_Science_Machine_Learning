{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datframe\n",
    "\n",
    "data='/Users/atul595525/Desktop/learning/Edureka_courses/Python_For_Data_Science/Module_6_Introduction_to_Machine_Learning_with_Python/BostonHousing.csv'\n",
    "\n",
    "df=pd.read_csv(data)\n",
    "\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating x and y variables\n",
    "\n",
    "X = df.iloc[:,0:13]\n",
    "\n",
    "Y =df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlation\n",
    "\n",
    "#CHECKING CORRELATION\n",
    "\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding correlation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_corr = df.iloc[:, 0:20].corr()\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(df_corr, cmap=\"Blues\", annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values\n",
    "print('Missing values:\\n{}'.format(df.isnull().sum()))\n",
    "\n",
    "# Find duplicated records\n",
    "print('\\nNumber of duplicated records: {}'.format(df.duplicated().sum()))\n",
    "\n",
    "# Find the unique values of 'diagnosis'.\n",
    "print('\\nUnique values of \"diagnosis\": {}'.format(df['label'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no missing values or duplicated records. Next the diagnosis distribution is checked.\n",
    "total = df['label'].count()\n",
    "male = df[df['label'] == \"male\"]['label'].count()\n",
    "print(\"male: \", male)\n",
    "print(\"female: \", total - male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode \"label\" to numerical values\n",
    "\n",
    "df['label'] = df['label'].map({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Preprocessing: label encoder and normalization\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "voice[\"label\"] = le.fit_transform(voice[\"label\"])\n",
    "le.classes_\n",
    "'''\n",
    "'''\n",
    "voice[:]=preprocessing.MinMaxScaler().fit_transform(voice)\n",
    "voice.head()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainning test split of data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.33,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model=LinearRegression()\n",
    "\n",
    "#trainning\n",
    "\n",
    "lr_model.fit(x_train,y_train)\n",
    "\n",
    "#testing or rpeediction\n",
    "\n",
    "pred_y = lr_model.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing coeeficients\n",
    "\n",
    "print(lr_model.coef_)\n",
    "print(lr_model.intercept_)\n",
    "print(lr_model.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)\n",
    "accuracy = regressor.score(x_test,y_test)\n",
    "print(accuracy*100,'%')\n",
    "\n",
    "# R squared value\n",
    "metrics.explained_variance_score(y_test, predictions)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "test_y, linear_predicted_rating = [1,2,3,4], [1,2,3,5]\n",
    "metrics.accuracy_score(test_y, linear_predicted_rating)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression Metrics\n",
    "\n",
    "In this section will review 3 of the most common metrics for evaluating predictions on regression machine learning problems:\n",
    "\n",
    "Mean Absolute Error.\n",
    "Mean Squared Error.\n",
    "R^2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Mean Absolute Error\n",
    "\n",
    "The Mean Absolute Error (or MAE) is the average of the absolute differences between predictions and actual values. \n",
    "It gives an idea of how wrong the predictions were.\n",
    "\n",
    "The measure gives an idea of the magnitude of the error, but no idea of the direction (e.g. over or under predicting).\n",
    "\n",
    "You can learn more about Mean Absolute error on Wikipedia.\n",
    "\n",
    "The example below demonstrates calculating mean absolute error on the Boston house price dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MAE: %.3f (%.3f)\") % (results.mean(), results.std())\n",
    "\n",
    "\n",
    "A value of 0 indicates no error or perfect predictions. Like logloss, this metric is inverted by the \n",
    "cross_val_score() function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Mean Squared Error\n",
    "\n",
    "The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the \n",
    "magnitude of error.\n",
    "\n",
    "Taking the square root of the mean squared error converts the units back to the original units of the output \n",
    "variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE).\n",
    "\n",
    "You can learn more about Mean Squared Error on Wikipedia.\n",
    "\n",
    "The example below provides a demonstration of calculating mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'neg_mean_squared_error'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"MSE: %.3f (%.3f)\") % (results.mean(), results.std())\n",
    "This metric too is inverted so tha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3. R^2 Metric\n",
    "\n",
    "The R^2 (or R Squared) metric provides an indication of the goodness of fit of a set of predictions to the actual values. In statistical literature, this measure is called the coefficient of determination.\n",
    "\n",
    "This is a value between 0 and 1 for no-fit and perfect fit respectively.\n",
    "\n",
    "You can learn more about the Coefficient of determination article on Wikipedia.\n",
    "\n",
    "The example below provides a demonstration of calculating the mean R^2 for a set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data\"\n",
    "names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "dataframe = pandas.read_csv(url, delim_whitespace=True, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:13]\n",
    "Y = array[:,13]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LinearRegression()\n",
    "scoring = 'r2'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"R^2: %.3f (%.3f)\") % (results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying logistic regresion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ln_model = LogisticRegression()\n",
    "ln_model.fit(train_x, train_y)\n",
    "\n",
    "predicted_data = ln_model.predict(test_x)\n",
    "\n",
    "metrics.accuracy_score(predicted_data, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=0).fit(train_x, train_y)\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(train_x, train_y)))\n",
    "\n",
    "predicted_data = tree.predict(test_x)\n",
    "#print(\"Accuracy on test set: {:.3f}\".format(tree.score(test_x, test_y)))\n",
    "\n",
    "metrics.accuracy_score(predicted_data, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train random forest model\n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0).fit(train_x, train_y)\n",
    "print(\"Random Forests\")\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(train_x, train_y)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(test_x, test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying NaiveBayes Calssification\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb=GaussianNB()\n",
    "\n",
    "gnb.fit(train_x, train_y)\n",
    "\n",
    "predicted_data = gnb.predict(test_x)\n",
    "\n",
    "metrics.accuracy_score(predicted_data, test_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of mislabelled points out of total %d points\")\n",
    "(df.shape[0], (test_y !=predicted_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying SVM\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = svm.SVC(kernel='linear')\n",
    "model.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_pred, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.classification_report(expected, predicted))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "'''\n",
    "\n",
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       0.93      0.99      0.96     13253\n",
    "          1       0.99      0.93      0.96     13324\n",
    "\n",
    "avg / total       0.96      0.96      0.96     26577\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Use LabelEncoder to encode the target variable in to numerical form and split the data such that 20% of the data is set aside for testing.\n",
    "\n",
    "#Preprocessing: label encoder and normalization\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df[\"Private\"] = le.fit_transform(df[\"Private\"])\n",
    "le.classes_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:]=preprocessing.MinMaxScaler().fit_transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Fit a linear svm from scikit learn and observe the accuracy. [Hint: Use Linear SVC]\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(metrics.classification_report(expected, predicted))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='rbf',C=10,gamma=0.01) # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Priciple component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=2)\n",
    "pca = PCA()\n",
    "x_train = pca.fit_transform(x_train)\n",
    "x_test = pca.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=5)\n",
    "x_train = lda.fit_transform(x_train, y_train)\n",
    "x_test = lda.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the Performance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print('Accuracy' + str(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un Supervised learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k means clustering\n",
    "\n",
    "#simple,understandabale\n",
    "#items automatically assigned to clsuter\n",
    "\n",
    "#cons\n",
    "\n",
    "#must define number of clusters\n",
    "#all items are forced into clsuters\n",
    "#unable to handle noisy data and filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "kmeans.fit(df_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans.labels_\n",
    "list(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique,counts = np.unique(kmeans.labels_,return_counts=True)\n",
    "\n",
    "dict(zip(unique,counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means with Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use elbow method to find optimal number of clusters\n",
    "wcss = []  # \"wcss\" stands for Within Cluster Squared Sum of Error also called 'inertia'\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for i in range(1,11):\n",
    "    kmeans_model = KMeans(n_clusters=i,\n",
    "                         init='k-means++',\n",
    "                          max_iter=300,\n",
    "                          n_init=10,\n",
    "                          random_state=42,\n",
    "                         )\n",
    "    kmeans_model.fit(X)  # training the model\n",
    "    wcss.append(kmeans_model.inertia_)\n",
    "\n",
    "print(wcss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), wcss)\n",
    "plt.title(\"Elbow method\")\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now using the elbow method we identified k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "# fitting K-Means to the dataset\n",
    "kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
    "y_means = kmeans.fit_predict(X)\n",
    "print(\"cluster numbers which input customers belong to:\")\n",
    "print(y_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the clusters\n",
    "plt.scatter(X[y_means == 0, 0], X[y_means == 0, 1], s=100, c='red', label='Cluster 1')\n",
    "plt.scatter(X[y_means == 1, 0], X[y_means == 1, 1], s=100, c='blue', label='Cluster 2')\n",
    "plt.scatter(X[y_means == 2, 0], X[y_means == 2, 1], s=100, c='green', label='Cluster 3')\n",
    "plt.scatter(X[y_means == 3, 0], X[y_means == 3, 1], s=100, c='cyan', label='Cluster 4')\n",
    "plt.scatter(X[y_means == 4, 0], X[y_means == 4, 1], s=100, c='magenta', label='Cluster 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the cluster plus centers/centroids\n",
    "plt.scatter(X[y_means == 0, 0], X[y_means == 0, 1], s=100, c='red', label='Cluster 1')\n",
    "plt.scatter(X[y_means == 1, 0], X[y_means == 1, 1], s=100, c='blue', label='Cluster 2')\n",
    "plt.scatter(X[y_means == 2, 0], X[y_means == 2, 1], s=100, c='green', label='Cluster 3')\n",
    "plt.scatter(X[y_means == 3, 0], X[y_means == 3, 1], s=100, c='cyan', label='Cluster 4')\n",
    "plt.scatter(X[y_means == 4, 0], X[y_means == 4, 1], s=100, c='magenta', label='Cluster 5')\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],\n",
    "           s=300, c='yellow', label='centroids')\n",
    "plt.title(\"Cluster of customers\")\n",
    "plt.xlabel(\"Annual Income\")\n",
    "plt.ylabel(\"Spending score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agglo = AgglomerativeClustering(n_clusters=4)\n",
    "predicted_values = agglo.fit_predict(df.iloc[:, 1:16])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(predicted_values, df[\"class_type\"].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error value\n",
    "\n",
    "print(\"Mean Squared Error value\")\n",
    "print(metrics.mean_squared_error(predicted_values, df[\"class_type\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hierarichal_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dendrogram: a dendrogram is a tree diagram frequently used to illustrate the \n",
    "#arrangements of clusters produced by Hierarichal_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('movie_metadata1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = data['budget'].values\n",
    "f2 = data['gross'].values\n",
    "\n",
    "# considering just first 10 values so thatf dendrogram can be show\n",
    "fb = f1[0:10]\n",
    "fg = f2[0:10]\n",
    "X = np.array(list(zip(fb,fg)))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, 'ward')\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, 'single')\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy C-means Clsutering \n",
    "\n",
    "#this is extension of K means clsuetring(Referred as soft clsustering), in which \n",
    "#each daat point can belong tio more than 1 clsuter\n",
    "\n",
    "#kmeans tries to find the hard clsuter(where each point belong to one cluster) and fuzzy c means cluster finds the soft cluster\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
